# 大语言模型部署报告  
- 2351289周慧星
- **项目链接**：[魔搭社区项目](https://modelscope.cn/models/xing0518/AI4_LLM/summary)/[GitHub 代码仓库](https://github.com/xing05188/xing/tree/main/AI4_LLM)  

## 一、实验概述  
本次实验基于魔搭社区部署大语言模型，通过问答测试对比 **通义千问Qwen-7B-Chat**、**智谱ChatGLM3-6B**、**百川Baichuan2-7B-Chat**、**DeepSeek-R1** 的性能，分析其在中文语义理解任务中的表现差异。  

## 二、模型下载 
通过命令行下载目标模型：  
```bash  
git clone https://www.modelscope.cn/qwen/Qwen-7B-Chat.git  
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git  
git clone https://www.modelscope.cn/baichuan-inc/Baichuan2-7B-Chat.git  
```  
**部署成功标志**：命令行返回模型文件下载完成信息。  


## 三、问答测试设计  
### 测试问题（中文语义理解）
一共有7个问答测试，查看不同模型的回答：
1. **冬夏穿衣差异**：  
   *请说出以下两句话区别在哪里？ 1、冬天：能穿多少穿多少 2、夏天：能穿多少穿多少*  
2. **单身狗原因悖论**：  
   *请说出以下两句话区别在哪里？单身狗产生的原因有两个，一是谁都看不上，二是谁都看不上*  
3. **逻辑嵌套问题**：  
   *他知道我知道你知道他不知道吗？ 这句话里，到底谁不知道*  
4. **断句歧义问题**：  
   *明明明明明白白白喜欢他，可她就是不说。 这句话里，明明和白白谁喜欢谁？*  
5. **多义词语境分析**：  
   *领导：你这是什么意思？ 小明：没什么意思。意思意思。 领导：你这就不够意思了。 小明：小意思，小意思。领导：你这人真有意思。 小明：其实也没有别的意思。 领导：那我就不好意思了。 小明：是我不好意思。请问：以上“意思”分别是什么意思。*  
6. **断句歧义分析**：  
   *“下雨天留客天留我不留”，请用不同断句方式解释这句话的含义，并说明哪种断句更符合中文表达习惯。*  
7. **逻辑推理题**：  
   *甲说：“乙在说谎。”乙说：“丙在说谎。”丙说：“甲和乙都在说谎。”请问：谁在说谎？谁在说真话？*  


### 模型部署代码
#### 共用代码，将模型名替换即可。循环回答7个问题。
```python  
from transformers import TextStreamer, AutoTokenizer, AutoModelForCausalLM
import torch
model_name = "/mnt/data/Qwen-7B-Chat"
prompt = [
    "请说出以下两句话区别在哪里? 1､冬天:能穿多少穿多少 2､夏天:能穿多少穿多少",
    "请说出以下两句话区别在哪里？单身狗产生的原因有两个，一是谁都看不上，二是谁都看不上",
    "他知道我知道你知道他不知道吗？ 这句话里，到底谁不知道",
    "明明明明明白白白喜欢他，可她就是不说。 这句话里，明明和白白谁喜欢谁？",
    "领导：你这是什么意思？ 小明：没什么意思。意思意思。 领导：你这就不够意思了。 小明：小意思，小意思。领导：你这人真有意思。 小明：其实也没有别的意思。领导：那我就不好意思了。 小明：是我不好意思。请问：以上“意思”分别是什么意思。",
    "“下雨天留客天留我不留”，请用不同断句方式解释这句话的含义，并说明哪种断句更符合中文表达习惯。",
    "甲说：“乙在说谎。”乙说：“丙在说谎。”丙说：“甲和乙都在说谎。”请问：谁在说谎？谁在说真话？"
]
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    trust_remote_code=True  # 允许加载远程代码（部分模型需此参数）
)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    trust_remote_code=True,
    torch_dtype=torch.float32
).eval()  # 切换为推理模式
for i in range(7):
    print(f"\n===== 问题 {i+1} =====\n")
    inputs = tokenizer(prompt[i], return_tensors="pt").input_ids
    streamer = TextStreamer(tokenizer)
    outputs = model.generate(inputs, streamer=streamer, max_new_tokens=300) 
```   
### （一）Qwen-7B-Chat 测试  
#### 1. 模型部署
**部署成功输出**： 
![](images/1.png)

#### 2. 测试结果  
![](images/3.png)
![](images/4.png)
![](images/5.png)
  
### （二）ChatGLM3-6B 测试  
#### 1. 模型部署
**部署成功输出**：
![](images/2.png)

#### 2. 测试结果  
![](images/6.png)
![](images/7.png)
![](images/8.png)
  


### （三）Baichuan2-7B-Chat 测试  
#### 1. 模型部署
**部署成功输出**：
![](images/9.png)
#### 2. 测试结果  
![](images/10.png)
![](images/12.png)
![](images/13.png)
 
### （四）DeepSeek-R1 测试  
#### 1. 模型部署
由于DeepSeek-R1模型太大，所以未部署，在官网进行测试。
#### 2. 测试结果  
![](images/11.png)
![](images/14.png)
![](images/15.png)


## 四、大语言模型横向对比分析（通义千问Qwen-7B-Chat、智谱ChatGLM3-6B、百川Baichuan2-7B-Chat、DeepSeek-R1）
---

### **一、模型核心维度对比**

| **维度**          | **通义千问Qwen-7B-Chat**                | **智谱ChatGLM3-6B**                  | **百川Baichuan2-7B-Chat**              | **DeepSeek-R1**                        |
|-------------------|-----------------------------------------|---------------------------------------|-----------------------------------------|----------------------------------------|
| **架构**          | Transformer解码器，支持8K上下文，多模态 | GLM混合精度架构，轻量级对话优化        | 类Llama架构，轻量化设计                 | 强化逻辑推理的Transformer，4K上下文     |
| **训练数据**      | 2.2万亿Token（多语言、代码、插件）      | 中文互联网语料（未公开规模）           | 1.2万亿Token（通用文本+少量代码）        | 8000亿Token（逻辑推理数据集）           |
| **核心优势**      | 多模态支持强、长上下文精准处理          | 中文语义细腻、部署轻量化               | 开源友好、响应速度快                    | 逻辑推理能力突出（唯一全对问题7）       |
| **主要短板**      | 数学能力弱、端侧部署需硬件支持          | 逻辑推理断层（如悖论问题）             | 语义歧义处理差（问题1/4误判）            | 无多模态支持、场景单一                  |
| **典型场景**      | 多模态对话、代码生成、企业级插件调用    | 中文闲聊、知识问答                     | 轻量级对话、快速响应                    | 逻辑推理、复杂问答分析                  |

---

### **二、关键维度对比解析**

#### 1. **逻辑推理能力**
- **DeepSeek-R1**：唯一在**问题7（说谎推理）**中全对的模型，通过分层语义解析避免逻辑矛盾。  
- **Qwen-7B-Chat**：正确推理但依赖上下文链，过程较复杂。  
- **ChatGLM3-6B/Baichuan2-7B-Chat**：均出现逻辑断层，前者假设乙真时未发现矛盾，后者结论自相矛盾。

#### 2. **中文语义处理**
- **Qwen-7B-Chat**：在**问题5（“意思”多义解析）**中表现最佳，精准识别不同语境下的含义（如“意思意思”指“礼节性表示”）。  
- **ChatGLM3-6B**：部分正确（如“真有意思”解读为“有趣”），但“不够意思”误判为“不够充分”。  
- **Baichuan2-7B-Chat**：问题4（“明明白白”指代）完全误判，认为“无法确定谁喜欢谁”。

#### 3. **多模态与扩展性**
- **Qwen-7B-Chat**：唯一支持多模态的模型，适合需要图文/音视频交互的场景。  
- **DeepSeek-R1**：专注逻辑推理，缺乏多模态能力，但在数学/逻辑题解析中优势显著（如问题3明确“他不知道”为核心）。

---

### **三、差异化亮点与不足**

| **模型**          | **差异化亮点**                                                                 | **主要不足**                                  |
|-------------------|-------------------------------------------------------------------------------|----------------------------------------------|
| **Qwen-7B**       | 首创“Thinker-Talker”双核架构，支持端到端音视频交互。                          | 数学能力弱，端侧部署需硬件支持。             |
| **ChatGLM3**      | 依托GLM生态，中文场景适配性强。                                               | 多轮对话连贯性差，逻辑断层明显。             |
| **Baichuan2**     | 开源社区活跃，轻量化设计响应快。                                              | 语义歧义处理差，缺乏垂直优化。               |
| **DeepSeek-R1**   | 逻辑推理分层解析（如问题7唯一全对），数学/逻辑题优势显著。                    | 场景单一，无多模态支持。                     |

---

### **四、典型案例表现**

| **问题场景**            | **最佳模型**       | **关键表现**                                                                 |
|-------------------------|--------------------|-----------------------------------------------------------------------------|
| **问题7（说谎推理）**   | DeepSeek-R1        | 唯一全对，直接拆解逻辑链。Qwen依赖上下文，ChatGLM3/Baichuan2结论矛盾。      |
| **问题5（多义词解析）** | Qwen-7B-Chat       | 精准识别不同语境下的“意思”。ChatGLM3部分误判，Baichuan2混淆含义。           |
| **问题3（嵌套知道）**   | Qwen-7B-Chat       | 解析复杂但正确，ChatGLM3误判“悖论无解”，Baichuan2忽略关键信息。             |

---

### **总结：模型选择建议**
- **通用对话/多模态**：选Qwen-7B-Chat（全场景覆盖，支持插件）。  
- **中文闲聊/轻量化**：选ChatGLM3-6B（性价比高，适合C端产品）。  
- **逻辑推理/垂直场景**：选DeepSeek-R1（精准解析，适合教育、客服）。  
- **低成本快速验证**：选Baichuan2-7B-Chat（开源友好，适合原型开发）。  




